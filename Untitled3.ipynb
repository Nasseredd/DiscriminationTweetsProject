{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\zakof\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string \n",
    "import re \n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import PorterStemmer \n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "from nltk.corpus import wordnet\n",
    "import warnings\n",
    "nltk.download('wordnet')\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'Data/data.csv'\n",
    "dataframe = pd.read_csv(file, error_bad_lines=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(df):\n",
    "    '''\n",
    "        df : DataFrame \n",
    "    '''\n",
    "    \n",
    "    # Delete IDs\n",
    "    df.drop('ID', axis=1, inplace=True)\n",
    "    \n",
    "    # First encoding \n",
    "    df['Label'].replace('none', 'not racist', inplace=True)\n",
    "    df['Label'].replace('racism', 'racist', inplace=True)\n",
    "    \n",
    "    i = 0 \n",
    "    for i in range(df['Tweets'].shape[0]):\n",
    "        # Remove ids @ \n",
    "        df['Tweets'][i] = re.sub(r'@\\S+', '', df['Tweets'][i])\n",
    "        \n",
    "        # Remove punctuation\n",
    "        df['Tweets'][i] = \"\".join([char for char in df['Tweets'][i] if char not in string.punctuation])\n",
    "        \n",
    "        # Uppercase -> Lowercase \n",
    "        df['Tweets'][i] = df['Tweets'][i].lower()\n",
    "        \n",
    "        # Delete Url \n",
    "        df['Tweets'][i] = re.sub(r'http\\S+', '', df['Tweets'][i])\n",
    "        \n",
    "        \n",
    "        # Delete characters \n",
    "        df['Tweets'][i] = re.sub(\"ð|ÿ|‘|œ|¦|€|˜|™|¸|¤|‚|©|¡|…|”|“|‹|š|±|³|iâ|§|„|\", '', df['Tweets'][i]) \n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(df):\n",
    "    df['Tweets'] = df.apply(lambda row: nltk.word_tokenize(row['Tweets']), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaning(dataframe)\n",
    "tok=tokenization(dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok['Tweets']=tok['Tweets'].apply(lambda x: [item for item in x if item not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[video, peshmerga, decimating, isis, far, inte...</td>\n",
       "      <td>not racist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[oh, really, instant, restaurants, thats, shoc...</td>\n",
       "      <td>not racist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[rt, hasnt, good, weeks, isis, new, front, ope...</td>\n",
       "      <td>not racist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[rt, donât, need, femisnsn, men, carry, heavy,...</td>\n",
       "      <td>not racist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[19, vast, majority]</td>\n",
       "      <td>not racist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16044</th>\n",
       "      <td>[rt, want, equal, rights, still, want, seat, b...</td>\n",
       "      <td>sexism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16045</th>\n",
       "      <td>[rt, go, ahead, call, sexist, scandalous, wome...</td>\n",
       "      <td>sexism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16046</th>\n",
       "      <td>[ive, epic, always, kept, plugged, plugged, us...</td>\n",
       "      <td>not racist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16047</th>\n",
       "      <td>[think, daesh, planning, second, battle, trenc...</td>\n",
       "      <td>not racist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16048</th>\n",
       "      <td>[rt, skin, green, colors, suit, wear, ripped, ...</td>\n",
       "      <td>not racist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16049 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweets       Label\n",
       "0      [video, peshmerga, decimating, isis, far, inte...  not racist\n",
       "1      [oh, really, instant, restaurants, thats, shoc...  not racist\n",
       "2      [rt, hasnt, good, weeks, isis, new, front, ope...  not racist\n",
       "3      [rt, donât, need, femisnsn, men, carry, heavy,...  not racist\n",
       "4                                   [19, vast, majority]  not racist\n",
       "...                                                  ...         ...\n",
       "16044  [rt, want, equal, rights, still, want, seat, b...      sexism\n",
       "16045  [rt, go, ahead, call, sexist, scandalous, wome...      sexism\n",
       "16046  [ive, epic, always, kept, plugged, plugged, us...  not racist\n",
       "16047  [think, daesh, planning, second, battle, trenc...  not racist\n",
       "16048  [rt, skin, green, colors, suit, wear, ripped, ...  not racist\n",
       "\n",
       "[16049 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
