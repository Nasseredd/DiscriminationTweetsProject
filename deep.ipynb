{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6xk_fT6SCxk"
      },
      "source": [
        "##bibliothéques \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69dtvpwUPq0X"
      },
      "source": [
        "import torchtext\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.data import Field, TabularDataset, BucketIterator"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFQ75mdHwjLq"
      },
      "source": [
        "##Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DG1Tgkc2v-HQ"
      },
      "source": [
        "import spacy\n",
        "sapcy_en = spacy.load('en')\n",
        "def tokenizer(text):\n",
        "   return [tok.text for tok in sapcy_en.tokenizer(text)]\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1fKz5tSt-8e"
      },
      "source": [
        "##Definition des prétraitements sur le texte"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs-kWLQ8t-Gu"
      },
      "source": [
        "TEXT = Field(sequential = True, lower = True, include_lengths=False, pad_token = \"<pad>\", unk_token = \"<unk>\", batch_first = True, tokenize = tokenizer)\n",
        "LABELS = Field(sequential = False, use_vocab = False)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OAvVpm3xHhw"
      },
      "source": [
        "##Création des datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5nO7ECJxMDO"
      },
      "source": [
        "train_dataset, test_dataset = TabularDataset.splits(path='/content/sample_data', format='csv',\n",
        "                                                    train='train.csv', \n",
        "                                                    test='test.csv', \n",
        "                                                    fields=[('text', TEXT), ('labels', LABELS)])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azNCNN-8IaE7",
        "outputId": "bb408fb1-8d5f-46db-aa57-a387d04dbb8f"
      },
      "source": [
        "train_dataset.labels\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Dataset.__getattr__ at 0x7f8cd21467d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHjbsm7Qr72X"
      },
      "source": [
        "##Géstion des batchs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcdcuFWpt7Iz"
      },
      "source": [
        "device = torch.device('cuda')\n",
        "train_iter, test_iter = BucketIterator.splits((train_dataset, test_dataset), batch_sizes=(16, 256), sort_key = lambda x:len(x.text), device=device, sort_within_batch = True, shuffle = True, repeat=False)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8W-GX4nwDwP"
      },
      "source": [
        "##Gestion du vocabulaire et des word Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAPEqx6mwNzt",
        "outputId": "621ad924-f0e4-4679-90b1-e1beab1f13d8"
      },
      "source": [
        "glove = torchtext.vocab.GloVe(name='6B', dim=50)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [06:30, 2.21MB/s]                           \n",
            " 99%|█████████▉| 397723/400000 [00:16<00:00, 25644.22it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaPjiONP9PHL"
      },
      "source": [
        "TEXT.build_vocab(train_dataset, min_freq=2, vectors = glove)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQ76RN1R987F",
        "outputId": "a61e549e-e003-442a-9c60-b86dd3d609f3"
      },
      "source": [
        "len(TEXT.vocab)\n",
        "#TEXT.vocab.vectors.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15327"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCo7DEFp-p_8"
      },
      "source": [
        "Visualisation des batch de données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwXWDlxU-iy6",
        "outputId": "0bd1b80c-8948-439c-ab25-80b63b99ef4b"
      },
      "source": [
        "batch = next(iter(train_iter))\n",
        "batch"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[torchtext.data.batch.Batch of size 16]\n",
              "\t[.text]:[torch.cuda.LongTensor of size 16x5 (GPU 0)]\n",
              "\t[.labels]:[torch.cuda.LongTensor of size 16 (GPU 0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xl2or3na_ZA6",
        "outputId": "3c424bcd-8b23-4290-b6b3-3ffaf21f5fcc"
      },
      "source": [
        "batch.text.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHAYm4GS_y-Y"
      },
      "source": [
        "Création du modéle "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_B_8s6uJ_4Tg"
      },
      "source": [
        "class LSTMModele(nn.Module):\n",
        "  def __init__(self, embedding_dim=50):\n",
        "      super(LSTMModele, self).__init__()\n",
        "      self.embeddings = nn.Embedding.from_pretrained(TEXT.vocab.vectors, freeze=False)\n",
        "      self.lstm = nn.LSTM(input_size = embedding_dim, hidden_size = embedding_dim, batch_first=True)\n",
        "      self.fc = nn.Linear(embedding_dim,2)\n",
        "  def forward(self, inputs):\n",
        "      embeds = self.embeddings(inputs)\n",
        "      outputs, (h_n,c_n) = self.lstm(embeds)\n",
        "      x = h_n[0]\n",
        "      x = self.fc(x)\n",
        "      return x\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7T_1Ey5DshJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgyeGlrKDk8c"
      },
      "source": [
        "Définition de l'op et de la loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilnRor-yDvxJ"
      },
      "source": [
        "net = LSTMModele(embedding_dim=50).to(device)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UQqr7XNEIBB",
        "outputId": "3e48a352-8757-4ee0-a315-35105426b04e"
      },
      "source": [
        "net"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMModele(\n",
              "  (embeddings): Embedding(15327, 50)\n",
              "  (lstm): LSTM(50, 50, batch_first=True)\n",
              "  (fc): Linear(in_features=50, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYcW34l8EQOv"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr = 0.001)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bX9RGEMCESmJ"
      },
      "source": [
        "##Boucle d'apprentissage "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VbO2loAEW7I",
        "outputId": "ed6e2725-e84f-44a2-d8e7-512cc2f52e97"
      },
      "source": [
        "%%time\n",
        "nb_epoche = 5 \n",
        "for epoch in range(nb_epoche):\n",
        "  for batch in train_iter:\n",
        "    data = batch.text.to(device)\n",
        "    labels = batch.labels.to(device)\n",
        "    outputs = net(data)\n",
        "    loss = criterion(outputs, labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print('epoch :' + str(epoch))\n",
        "\n",
        "print('end')\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch :0\n",
            "epoch :1\n",
            "epoch :2\n",
            "epoch :3\n",
            "epoch :4\n",
            "end\n",
            "CPU times: user 48.1 s, sys: 1.33 s, total: 49.4 s\n",
            "Wall time: 49.5 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRP-PMa-MX6B"
      },
      "source": [
        "Mesure des performances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53zKHNyQMeCM"
      },
      "source": [
        "import numpy as np\r\n",
        "all_labels = []\r\n",
        "all_preds = []\r\n",
        "\r\n",
        "with torch.no_grad():\r\n",
        "  for batch in test_iter:\r\n",
        "    data = batch.text.to(device)\r\n",
        "    labels = batch.labels.to(device)\r\n",
        "\r\n",
        "    outputs =net(data)\r\n",
        "    _, predicted = torch.max(outputs.data, 1)\r\n",
        "    all_preds.append(predicted.cpu().numpy())\r\n",
        "    all_labels.append(labels.cpu().numpy())\r\n",
        "\r\n",
        "all_labels = np.concatenate(all_labels)\r\n",
        "all_preds = np.concatenate(all_preds)\r\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vcsfcw3OEMN"
      },
      "source": [
        "Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsnJsTCBOG2n",
        "outputId": "ab29b6ad-2ca7-4cf6-88f2-95ca5b304604"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\r\n",
        "##accuracy_score(all_labels, all_preds)\r\n",
        "f1_score(all_labels, all_preds, average='weighted')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8938555351035558"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    }
  ]
}